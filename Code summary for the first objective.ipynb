{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Semi-analytical model and data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Magnetic force modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "import matplotlib as plt\n",
    "import math as m\n",
    "from numpy import sqrt, sin, cos, pi\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Delta funcion\n",
    "def delta(theta,alpha,r):\n",
    "    return 2*r*cos(alpha-theta)\n",
    "\n",
    "# Pxi plus\n",
    "def pxi_plus(r,z,h):\n",
    "    return r**2 + (z-h)**2\n",
    "\n",
    "# Pxi minus\n",
    "def pxi_minus(r,z,h):\n",
    "    return r**2 + z**2\n",
    "\n",
    "# Mag function\n",
    "def mag(J):\n",
    "    return J/(4*pi)\n",
    "\n",
    "# Auxiliary radius\n",
    "def r0(theta,R):\n",
    "    a = R\n",
    "    b = R\n",
    "    return a*b/sqrt(a**2*sin(theta)**2 + b**2*cos(theta)**2)\n",
    "\n",
    "# Computation of the magnetic field from the upper (plus) surface (dB_plus)\n",
    "def dB_plus(theta,r, alpha, z, R, h):\n",
    "    db_func = (2*(delta(theta,alpha,r)*r0(theta,R) - \n",
    "                  2*pxi_plus(r,z,h))/(4*pxi_plus(r,z,h) - \n",
    "                                      delta(theta,alpha,r)**2)/sqrt((r0(theta,R)*\n",
    "                                                                     (r0(theta,R)-delta(theta,alpha,r))+\n",
    "                                                                     pxi_plus(r,z,h))) + 4*sqrt(pxi_plus(r,z,h))/\\\n",
    "               (4*pxi_plus(r,z,h)-delta(theta,alpha,r)**2))*(z-h)\n",
    "    return db_func\n",
    "    \n",
    "# Computation of the magnetic field from the lower (minus) surface (dB_minus)\n",
    "def dB_minus(theta,r, alpha, z, R, h):\n",
    "    db_func = -(2*(delta(theta,alpha,r)*r0(theta,R) - \n",
    "                  2*pxi_minus(r,z,h))/(4*pxi_minus(r,z,h) - \n",
    "                                      delta(theta,alpha,r)**2)/sqrt((r0(theta,R)*\n",
    "                                                                     (r0(theta,R)-delta(theta,alpha,r))+\n",
    "                                                                     pxi_minus(r,z,h))) + 4*sqrt(pxi_minus(r,z,h))/\\\n",
    "                (4*pxi_minus(r,z,h)-delta(theta,alpha,r)**2))*(z)\n",
    "    return db_func\n",
    "\n",
    "# Computation of the total magnetic field from both surfaces (dB)\n",
    "def dB(theta,r, alpha, z, R, h):\n",
    "    return dB_plus(theta,r, alpha, z, R, h) + dB_minus(theta,r, alpha, z, R, h)\n",
    "\n",
    "# Semi-analytical model for magnetic force computation (triple_db)\n",
    "\n",
    "def triple_db(r_s,h1, pxi, R, h):\n",
    "    return tplquad(lambda theta,r,alpha: r*dB(theta,r, alpha, pxi+h, R, h),\n",
    "                   -pi,pi, lambda r: 0, lambda r: r_s, lambda r,alpha: -pi, lambda r,alpha: pi)[0] - \\\n",
    "tplquad(lambda theta,r,alpha: r*dB(theta,r, alpha, pxi+h+h1, R, h),-pi,pi, lambda r: 0, lambda r: r_s, \n",
    "        lambda r,alpha: -pi, lambda r,alpha: pi)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data generation\n",
    "\n",
    "The random numbers generated in this study following the Mersenne Twister generator [1].<br>\n",
    "[1] M. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator”, ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January pp.3–30 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from scipy.integrate import tplquad\n",
    "\n",
    "# Defining the constants\n",
    "mu0 = 4*pi*10**-7 # the magnetic permeability\n",
    "K = 1/4/pi/mu0 # auxiliary constant\n",
    "\n",
    "# Creating emty lists\n",
    "mF_r = [] # Magnetic force empty list\n",
    "para_r = [] # Empty list of parameters\n",
    "\n",
    "# Generating random parameters\n",
    "for item in range(116448):\n",
    "    R = random.randint(3,30)/1000 # Radius of upper magnet\n",
    "    h1 = random.randint(5,50)/1000 # Thickness of upper magnet\n",
    "    r_s = random.randint(3,30)/1000 # Radius of lower magnet\n",
    "    h = random.randint(5,50)/1000 # Thickness of lower magnet\n",
    "    pxi = random.randint(2,50)/1000 # Separation distance between two magnets\n",
    "    mF_r.append(K*triple_db(r_s,h1, pxi, R, h)) # Magnetic force computation and appending to mF_r list\n",
    "    para_r.append([R*1000,h1*1000,r_s*1000,h*1000,pxi*1000]) # Appending parameters to para_r list\n",
    "    \n",
    "# Saving generated data\n",
    "\n",
    "saved_file = open('mF_rr', 'wb') # mF_r is saved in mF_rr file\n",
    "pickle.dump(mF_r, saved_file)\n",
    "\n",
    "saved_file = open('para_rr', 'wb') # para_r is saved in para_rr file\n",
    "pickle.dump(para_rr, saved_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pickle\n",
    "\n",
    "# Loading magnetic force\n",
    "pick_in = open('mF_rr','rb')\n",
    "mF__r = pickle.load(pick_in)\n",
    "pick_in.close()\n",
    "\n",
    "# Loading parameters\n",
    "pick_in1 = open('para_rr','rb')\n",
    "para__r = pickle.load(pick_in1)\n",
    "pick_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cleansing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 116361, min: 0.013400648488270193\n"
     ]
    }
   ],
   "source": [
    "# Cleansing those parameters created the magnetic force less than or equal to 0.0134 (empirical)\n",
    "i = 0\n",
    "while i < len(mF__r):\n",
    "    if mF__r[i] <= 0.0134:\n",
    "        mF__r.pop(i)\n",
    "        para__r.pop(i)\n",
    "        i -= 1\n",
    "    i += 1   \n",
    "print(f'len: {len(mF__r)}, min: {min(mF__r)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float 64 into float 32\n",
    "import numpy as np\n",
    "\n",
    "mF__r = np.array(mF__r, dtype = np.float32)\n",
    "para__r = np.array(para__r, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assigning data\n",
    "\n",
    "X = para__r\n",
    "y = mF__r\n",
    "\n",
    "# Creating training and testing data\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.08,shuffle = True)\n",
    "\n",
    "# Creating traning and validation data\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test_val, y_test_val, test_size=0.5,shuffle = True)\n",
    "\n",
    "# Scaling data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep learning model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Bulding model\n",
    "model = Sequential()\n",
    "model.add(Dense(300,activation = 'relu'))\n",
    "model.add(Dense(300,activation = 'relu'))\n",
    "model.add(Dense(300,activation = 'relu'))\n",
    "model.add(Dense(300,activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Creating empty lists\n",
    "test_error =[]\n",
    "loss = []\n",
    "val_loss = []\n",
    "training_error =1\n",
    "val_error = 1\n",
    "index = 0\n",
    "test_los = 1\n",
    "\n",
    "# Time counting initiated\n",
    "start_time = time.clock()\n",
    "\n",
    "# Training process\n",
    "while (training_error > 0.065**2) or (test_los > 0.065**2):\n",
    "    model.fit(x=X_train, y=y_train, batch_size = 1024, validation_data=(X_valid,y_valid), verbose=1, shuffle=True)\n",
    "    test_error.append(model.evaluate(X_test, y_test))\n",
    "    loss.append(model.history.history['loss'][0])\n",
    "    val_loss.append(model.history.history['val_loss'][0])\n",
    "    index +=1\n",
    "    training_error = loss[index-1]\n",
    "    val_error = val_loss[index-1]\n",
    "    test_los = test_error[index-1]                                                              \n",
    "\n",
    "# Training time computation\n",
    "trained_time = time.clock() - start_time    \n",
    "\n",
    "# Visualizing training errors\n",
    "error_ = {'Training': loss, 'Validation': val_loss, 'Test': test_error}\n",
    "plt.plot(loss,label = 'Training',ls='--')\n",
    "plt.plot(val_loss,label = 'Validation',marker='o')\n",
    "plt.plot(test_error, label = 'Test')\n",
    "plt.xlim(0,13)\n",
    "plt.ylim(0,1450)\n",
    "error_df = pd.DataFrame(error_)\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "\n",
    "# Saving trained model\n",
    "model.save('trained_model_with_random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Comparion between predicted and semi-analytical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading trained model\n",
    "a_model = tf.keras.models.load_model('trained_model_with_random')\n",
    "\n",
    "# Preparing data for comparison\n",
    "X_val_1, X_val_2, y_val_1, y_val_2 = train_test_split(X_test, y_test, test_size = 0.25, shuffle = 'True')\n",
    "\n",
    "# Cleansing data empirically\n",
    "i=0\n",
    "while i < len(y_val_2):\n",
    "    if y_val_2[i]<=1:\n",
    "        y_val_2 = np.delete(y_val_2,i)\n",
    "        X_val_2 = np.delete(X_val_2,i,axis=0)\n",
    "        i -= 1\n",
    "    i+=1   \n",
    "\n",
    "# Predicting results\n",
    "y_val_pred = a_model.predict(X_val_2)\n",
    "\n",
    "# Visulazing errors\n",
    "err_per =[]\n",
    "\n",
    "for item in range(len(X_val_2)):\n",
    "    err = abs(y_val_pred[item][0]-y_val_2[item])/y_val_pred[item][0]*100\n",
    "    err_per.append(err)\n",
    "    \n",
    "# Heatmap visulization of the results\n",
    "# For the predicted results\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(y_val_pred,cmap=\"YlGnBu\",yticklabels=False)\n",
    "plt.ylabel('F(N)')\n",
    "plt.xlabel('(a)')\n",
    "plt.title('Predicted results')\n",
    "\n",
    "# For the Semi-analytical results\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(y_val_2_plot,cmap=\"YlGnBu\",yticklabels=False)\n",
    "plt.subplots_adjust(bottom=0.1, right=1.2, top=0.9)\n",
    "plt.ylabel('F(N)')\n",
    "plt.xlabel('(b)')\n",
    "plt.title('Semi-analytical results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Validating the results against the Finite Element Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Obtaining results\n",
    "# From semi-analytical model\n",
    "semi = [7.0217,7.5095,5.5064,10.4319,26.6690,59.7973,36.3253,27.6379,20.8733,15.8355,9.3697,5.7812,3.7149,2.4769,1.7065]\n",
    "\n",
    "# From the surrogate model (deep learning-based)\n",
    "surro = [7.0289,7.4741,5.5225,10.4672,26.6741,59.7948,36.3335,27.8493,20.8972,15.7654,9.3828,5.7943,3.7128,2.4402,1.6709]\n",
    "\n",
    "# From the Finite Element Analysis\n",
    "fea = [7.0229,7.5006,5.5309,10.4590,26.6530,59.8500,36.4390,27.6200,20.8680,15.8850,9.3773,5.7753,3.7046,2.4674,1.7005]\n",
    "\n",
    "# Visualizing the validation\n",
    "\n",
    "plt.scatter(range(len(fea)),semi,label='Semi-analytical model')\n",
    "plt.scatter(range(len(fea)),surro,label='Surrogate model',marker = '*')\n",
    "plt.scatter(range(len(fea)),fea,label='FEA model',marker = 'd')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('F (N)')\n",
    "plt.grid()\n",
    "\n",
    "# Error for surrogate and FEA\n",
    "e_surro_fea = []\n",
    "\n",
    "for i in range(len(fea)):\n",
    "    er = abs(surro[i]-fea[i])/fea[i]*100\n",
    "    e_surro_fea.append(er)\n",
    "    \n",
    "# Error for semi-analytical and FEA\n",
    "\n",
    "e_semi_fea = []\n",
    "\n",
    "for i in range(len(fea)):\n",
    "    er = abs(semi[i]-fea[i])/fea[i]*100\n",
    "    e_semi_fea.append(er)\n",
    "    \n",
    "# Computing the minimum, average and maximum errors\n",
    "np.min(e_semi_fea)\n",
    "np.mean(e_semi_fea)\n",
    "np.max(e_semi_fea)\n",
    "\n",
    "np.min(e_surro_fea)\n",
    "np.mean(e_surro_fea)\n",
    "np.max(e_surro_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance as perm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Feature importance analysis\n",
    "# Noted: different models should be used to evaluate the scoring \n",
    "# Relying solely on r2 may lead to misleading conclusion.\n",
    "# Papers to be read: Tarald O. Kvalseth, \"Cautionary note about R^2\"\n",
    "# Using R^2 with caution;; R_1^2 and R_1a^2 are good to judge the goodness of fit\n",
    "# for a model.. Other r_quared should not be used solely as they can cause misleading conclusion\n",
    "\n",
    "result_negmrs = perm(model, X_val_2, y_val_2, scoring = 'neg_root_mean_squared_error', n_repeats = 200, random_state=0)\n",
    "result_r2 = perm(model, X_val_2, y_val_2, scoring = 'r2', n_repeats = 200, random_state=0)\n",
    "#result_mse = perm(model, X_val_re, y_val_re, scoring = 'neg_mean_squared_error', n_repeats = 100, random_state=0)\n",
    "#result_mabe = perm(model, X_val_re, y_val_re, scoring = 'neg_median_absolute_error', n_repeats = 100, random_state=0)\n",
    "#result_meabe = perm(model, X_val_re, y_val_re, scoring = 'neg_mean_absolute_error', n_repeats = 100, random_state=0)\n",
    "#result_eve = perm(model, X_val_re, y_val_re, scoring = 'explained_variance', n_repeats = 100, random_state=0)\n",
    "# Normalize the importances\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#result_norm = scaler.fit_transform(result.importances_mean.reshape(-1,1))\n",
    "#result_2_norm = scaler.fit_transform(result_2.importances_mean.reshape(-1,1))\n",
    "\n",
    "# Bar plotting the importance results\n",
    "features = np.array(['R\\u2081', 'h\\u2081', 'R', 'h', '\\u03BE'])\n",
    "\n",
    "# Plotting feature importances per r2\n",
    "r2_sorted_idx = result_r2.importances_mean.argsort()\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(7,3.5))\n",
    "ax1.boxplot(result_r2.importances[r2_sorted_idx].T, \n",
    "            vert=False)\n",
    "ax1.set_yticklabels(features[r2_sorted_idx])\n",
    "ax1.set_xlabel('R-squared')\n",
    "ax1.set_ylabel('Features for deep learning model')\n",
    "ax1.set_title('(a) Boxplot of PFI')\n",
    "fig.suptitle('Permutation feature importance (PFI) per R-squared')\n",
    "\n",
    "#plt.setp(ax1.get_yticklabels(), rotation=90)\n",
    "ax1.grid('on')\n",
    "sns.heatmap(result_r2.importances[r2_sorted_idx][::-1], xticklabels=199, \n",
    "            yticklabels=False, cmap = 'YlGnBu')\n",
    "ax2.set_xlabel('Number of iterations')\n",
    "ax2.set_title('(b) Heatmap of PFI')\n",
    "\n",
    "#sns.heatmap(result_negmrs.importances[negmrs_sorted_idx][::-1], xticklabels=False, \n",
    " #           yticklabels=features[negmrs_sorted_idx][::-1], cmap = 'YlGnBu')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting feature importaces per loss function\n",
    "negmrs_sorted_idx = result_negmrs.importances_mean.argsort()\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6,3))\n",
    "ax1.boxplot(result_negmrs.importances[negmrs_sorted_idx].T, \n",
    "            vert=False)\n",
    "ax1.set_yticklabels(features[negmrs_sorted_idx])\n",
    "ax1.set_xlabel('PFI per loss function')\n",
    "ax1.set_ylabel('Features for deep learning model')\n",
    "ax1.set_title('(a) Boxplot of PFI')\n",
    "fig.suptitle('Permutation feature importance per loss function')\n",
    "\n",
    "#plt.setp(ax1.get_yticklabels(), rotation=90)\n",
    "ax1.grid('on')\n",
    "sns.heatmap(result_negmrs.importances[negmrs_sorted_idx][::-1], xticklabels=199, \n",
    "            yticklabels=False, cmap = 'YlGnBu')\n",
    "ax2.set_xlabel('Number of permutation')\n",
    "ax2.set_title('(b) Heatmap of PFI')\n",
    "\n",
    "#sns.heatmap(result_negmrs.importances[negmrs_sorted_idx][::-1], xticklabels=False, \n",
    " #           yticklabels=features[negmrs_sorted_idx][::-1], cmap = 'YlGnBu')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#ax2.set\n",
    "#ax2.boxplot(result_r2.importances[r2_sorted_idx].T, \n",
    " #           vert=True, labels=features[r2_sorted_idx])\n",
    "#ax2.grid('on')\n",
    "#fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6,5))\n",
    "plt.figure()\n",
    "plt.boxplot(result_negmrs.importances[negmrs_sorted_idx].T, \n",
    "            vert=False)\n",
    "plt.set_yticklabels(features[negmrs_sorted_idx])\n",
    "\n",
    "#plt.setp(ax1.get_yticklabels(), rotation=90)\n",
    "plt.grid('on')\n",
    "sns.heatmap(result_negmrs.importances[negmrs_sorted_idx][::-1], xticklabels=False, \n",
    "            yticklabels=False, cmap = 'YlGnBu')\n",
    "#sns.heatmap(result_negmrs.importances[negmrs_sorted_idx][::-1], xticklabels=False, \n",
    " #           yticklabels=features[negmrs_sorted_idx][::-1], cmap = 'YlGnBu')\n",
    "    \n",
    "plt.tight_layout()\n",
    "ax1.barh([1,2,3,4,5],result_norm.T[0])\n",
    "ax2.bar([1,2,3,4,5],result_2_norm[0])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "sns.heatmap(result.importances)\n",
    "x_ = np.arange(100)\n",
    "y_ = [item for item in result.importances_mean]\n",
    "plt.bar(x_, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Web-based Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Back-end module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Main body\n",
    "image_folder = os.path.join('static', 'images')\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = image_folder\n",
    "scaler = pickle.load(open('scaler_ran', 'rb'))\n",
    "filename = os.path.join(app.config['UPLOAD_FOLDER'], 'levitated_cylinders.png')\n",
    "plus_arrow = os.path.join(app.config['UPLOAD_FOLDER'], 'Plus_arrow.png')\n",
    "minus_arrow = os.path.join(app.config['UPLOAD_FOLDER'], 'Minus_arrow.png')\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def enter_parameters():\n",
    "\treturn render_template('mag_in.html', Fig = 'Fig.1 - Parameters of levitated cylinders', figure_geo = filename, \n",
    "                           arrow_J_1 = minus_arrow, arrow_J = plus_arrow, \n",
    "\tarrow_F = plus_arrow, J = 1, J_1 = -1, predicted_force = 11.546, R = 10, h = 10, R_1 = 10, h_1 = 10, xi = 10)\n",
    "@app.route('/predict', methods = ['POST'])\n",
    "def result():\n",
    "\tmodel = tf.keras.models.load_model('trained_model_with_random')\n",
    "\tfeatures = [np.float32(para) for para in request.form.values()]\n",
    "\tmodel_features = np.array([[features[4], features[5], features[1], features[2], features[6]]])\n",
    "\tmodel_features = scaler.transform(model_features)\n",
    "\tmag_force = round(-1*features[0]*features[3]*model.predict(model_features)[0][0],3)\n",
    "\n",
    "\treturn render_template('mag_in.html', Fig = 'Fig.2 - Schematic of predicted results', predicted_force = mag_force, \n",
    "                           figure_geo = filename, \n",
    "\tarrow_J_1 = minus_arrow if features[3] < 0 else plus_arrow, arrow_J = minus_arrow if features[0] < 0 else plus_arrow,\n",
    "\tarrow_F = minus_arrow if mag_force < 0 else plus_arrow, J = features[0], R = features[1], h = features[2],\n",
    "\t J_1 = features[3], R_1 = features[4], h_1 = features[5], xi = features[6])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tapp.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Front-end module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang = 'en'>\n",
    "<head>\n",
    "\t<title>DEMAGFO</title>\n",
    "\t<meta charset = 'UTF-8'>\n",
    "\t<meta name = 'description' content = 'Computing magnetic forces\n",
    "\tbetween permanent magnets using machine learning'>\n",
    "\t<meta name = 'author' content = 'Van Tai Nguyen, Michael and Matthew from University of Queensland'>\n",
    "\t<meta name = 'keywords' content = 'Deep learning, magnetic force, levitation force\n",
    "\tmagnetic cylinders'>\n",
    "\t<meta name = 'viewport' content = 'width=device-width, initial-scale=1.0'>\n",
    "</head>\n",
    "<style>\n",
    "div.absolute_Fig {\n",
    "\tposition: absolute;\n",
    "\ttop: 60px;\n",
    "\tright: 300px;\n",
    "\twidth: 350px;\n",
    "\theight:350px;\n",
    "}\n",
    "\n",
    "div.absolute_J_1 {\n",
    "\tposition: absolute;\n",
    "\ttop: 70px;\n",
    "\tright: 138px;\n",
    "\twidth: 350px;\n",
    "\theight:350px;\n",
    "}\n",
    "\n",
    "div.absolute_J {\n",
    "\tposition: absolute;\n",
    "\ttop: 155px;\n",
    "\tright: 141px;\n",
    "\twidth: 350px;\n",
    "\theight:350px;\n",
    "}\n",
    "\n",
    "div.absolute_F {\n",
    "\tposition: absolute;\n",
    "\ttop: -30px;\n",
    "\tright: -234px;\n",
    "\twidth: 350px;\n",
    "\theight:350px;\n",
    "}\n",
    "\n",
    "</style>\n",
    "<body style = 'background-color:#FFFFFF'>\n",
    "\t\n",
    "\t<form action='http://localhost:5000/predict' method='post'>\n",
    "\t\t<!--Input the geometrical parameters of the cylinders-->\n",
    "\t\t<!--Input the geometrical parameters of the first cylinder-->\n",
    "\t\t<h2 style = 'color:blue; background-color:#99FFFF;text-align:center;' >Computing Magnetic Forces between Permanent Magnets using a Machine Learning based Data-Driven Model</h2>\n",
    "\t\t<h4>Input the material property and geometrical parameters of the lower cylinder.</h4>\n",
    "\t\t<p>Remanence (J): <input type='text' name='J' placeholder =  '{{J}} (T)'/> </p>\n",
    "\t\t<p>Radius (R): <input type='text' name='R' placeholder = '{{R}} (mm)'/></p>\n",
    "\t\t\n",
    "\t\t<p>Height (h): <input type='text' name='h' placeholder = '{{h}} (mm)'/></p>\n",
    "\t\t\n",
    "\n",
    "\t\t<!--Input the geometrical parameters of the second cylinder-->\n",
    "\t\t<h4>Input the material property and geometrical parameters of the upper cylinder.</h4>\n",
    "\t\t<p>Remanence (J<sub>1</sub>): <input type='text' name='J_1'\n",
    "\t\tplaceholder = '{{J_1}} (T)'/></p>\n",
    "\t\t\n",
    "\t\t<p>Radius (R<sub>1</sub>): <input type='text' name='R_1' placeholder = '{{R_1}} (mm)'/></p>\n",
    "\t\t\n",
    "\t\t<p>Height (h<sub>1</sub>): <input type='text' name='h_1' placeholder = '{{h_1}} (mm)'/></p>\n",
    "\t\t\n",
    "\n",
    "\t\t<!--Input the separation distance between the cylinders-->\n",
    "\t\t<h4>Input the separation distance between the cylinders.</h4>\n",
    "\t\t<p>Separation distance (&#958): <input type='text' name='&#958' placeholder = '{{xi}} (mm)'/></p>\n",
    "\n",
    "\t\t<p style = 'color: red;'><b>Magnetic force F: {{predicted_force}} (N)</b></p>\n",
    "\t\t\n",
    "\t\t<p><input type='Submit' value='Predict'/></p>\n",
    "\n",
    "\t\t<p style = 'color: #000; background-color:#CCCCFF';><i>This work has the Creative Commons license of 4.0 (CC BY 4.0) which is free to adapt and share, but not for commercial purposes. This license belongs to the Univesrity of Queensland (UQ). Authors: Nguyen, Michael and Matthew from UQ.</i></p>\n",
    "\n",
    "\n",
    "\t</form>\n",
    "\t\t<div class = 'absolute_Fig'> <img src = '{{figure_geo}}' alt = 'Levitated_cylinders' width = '320'\n",
    "\t\theight = '370'> \n",
    "\t\t\t<p> {{Fig}} </p>\n",
    "\t\t</div>\n",
    "\n",
    "\t\t<div class = 'absolute_J_1'> <img src = '{{arrow_J_1}}' alt = 'arrow_J_1' width = '12'\n",
    "\t\theight = '56'> \n",
    "\n",
    "\t\t<div class = 'absolute_J'> <img src = '{{arrow_J}}' alt = 'arrow_J' width = '12'\n",
    "\t\theight = '56'> \n",
    "\t\t\n",
    "\t\t<div class = 'absolute_F'> <img src = '{{arrow_F}}' alt = 'arrow_F' width = '12'\n",
    "\t\theight = '56'> \n",
    "</body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
